    <SUBSECTION>
      <NAME>
  Examples of Nondeterministic Programs
      </NAME>

      <LABEL NAME="sec:amb-examples"/>
      <TEXT>
  Section<SPACE/><REF NAME="sec:amb-implementation"/> describes the implementation of
  the <SCHEMEINLINE>amb</SCHEMEINLINE> evaluator.  First, however, we give some examples of how
  it can be used.  The advantage of nondeterministic programming is that
  we can suppress the details of how search is carried out, thereby
  <INDEX>abstraction<SUBINDEX>search@of search in nondeterministic programming</SUBINDEX></INDEX>
  expressing our programs at a higher level of abstraction.
      </TEXT>

      <SUBHEADING>
  <NAME>Logic Puzzles</NAME>
      </SUBHEADING>

      <INDEX>puzzles<SUBINDEX>logic puzzles|(</SUBINDEX></INDEX>
      <INDEX>logic puzzles|(</INDEX>
      <INDEX>nondeterministic programs<SUBINDEX>logic puzzles|(</SUBINDEX></INDEX>

      <TEXT>
  <INDEX>Dinesman, Howard P.</INDEX>
  The following puzzle (taken from <CITATION>Dinesman 1968</CITATION>) 
  is typical of a large class of simple logic puzzles:

  <BLOCKQUOTE>
    Baker, Cooper, Fletcher, Miller, and Smith live on different floors of
    an apartment house that contains only five floors.  Baker does not
    live on the top floor.  Cooper does not live on the bottom floor.
    Fletcher does not live on either the top or the bottom floor.  Miller
    lives on a higher floor than does Cooper.  Smith does not live on a
    floor adjacent to Fletcher<APOS/>s.  Fletcher does not live on a floor
    adjacent to Cooper<APOS/>s.  Where does everyone live?
  </BLOCKQUOTE>

  We can determine who lives on each floor in a straightforward way by
  enumerating all the possibilities and imposing the given
  restrictions:<FOOTNOTE>Our program uses the following
    <SPLITINLINE><SCHEME>procedure</SCHEME><JAVASCRIPT>function</JAVASCRIPT></SPLITINLINE>
    to determine 
    if the elements of a list are distinct:
    <SNIPPET>
      <SCHEME>
        <!--  \indcode*{distinct?} -->
        (define (distinct? items)
        (cond ((null? items) true)
              ((null? (cdr items)) true)
              ((member (car items) (cdr items)) false)
              (else (distinct? (cdr items)))))
      </SCHEME>
    </SNIPPET>
    <!--  \indcode{member} -->
    <SCHEMEINLINE>Member</SCHEMEINLINE> is like <SCHEMEINLINE>memq</SCHEMEINLINE> except that it uses <SCHEMEINLINE>equal?</SCHEMEINLINE> instead
    of <SCHEMEINLINE>eq?</SCHEMEINLINE> to test for equality.
  </FOOTNOTE>

  <SNIPPET>
    <SCHEME>
      <!--  \indcode*{multiple-dwelling} -->
      (define (multiple-dwelling)
      (let ((baker (amb 1 2 3 4 5))
            (cooper (amb 1 2 3 4 5))
            (fletcher (amb 1 2 3 4 5))
            (miller (amb 1 2 3 4 5))
            (smith (amb 1 2 3 4 5)))
      (require
      (distinct? (list baker cooper fletcher miller smith)))
      (require (not (= baker 5)))
      (require (not (= cooper 1)))
      (require (not (= fletcher 5)))
      (require (not (= fletcher 1)))
      (require (&gt; miller cooper))
      (require (not (= (abs (- smith fletcher)) 1)))
      (require (not (= (abs (- fletcher cooper)) 1)))
      (list (list 'baker baker)
            (list 'cooper cooper)
            (list 'fletcher fletcher)
            (list 'miller miller)
            (list 'smith smith))))
    </SCHEME>
  </SNIPPET>
      </TEXT>

      <TEXT>
  Evaluating the expression <SPLITINLINE><SCHEME><SCHEMEINLINE>(multiple-dwelling)</SCHEMEINLINE></SCHEME><JAVASCRIPT><JAVASCRIPTINLINE>???</JAVASCRIPTINLINE></JAVASCRIPT></SPLITINLINE> produces the
  result
  <SNIPPET>
    <SCHEME>
      ((baker 3) (cooper 2) (fletcher 4) (miller 5) (smith 1))
    </SCHEME>
  </SNIPPET>
      </TEXT>

      <TEXT>
  Although this simple
  <SPLITINLINE><SCHEME>procedure</SCHEME><JAVASCRIPT>function</JAVASCRIPT></SPLITINLINE>
  works, it is very slow.
  Exercises<SPACE/><REF NAME="ex:better-multiple-dwelling1"/>
  and<SPACE/><REF NAME="ex:better-multiple-dwelling2"/> discuss some possible
  improvements.
  <INDEX>nondeterministic programs<SUBINDEX>logic puzzles|)</SUBINDEX></INDEX>
      </TEXT>

      <EXERCISE>
  Modify the multiple-dwelling
  <SPLITINLINE><SCHEME>procedure</SCHEME><JAVASCRIPT>function</JAVASCRIPT></SPLITINLINE>
  to omit the requirement that
  Smith and Fletcher do not live on adjacent floors.  How many solutions
  are there to this modified puzzle?
      </EXERCISE>

      <EXERCISE>
  Does the order of the restrictions in the multiple-dwelling
  <SPLITINLINE><SCHEME>procedure</SCHEME><JAVASCRIPT>function</JAVASCRIPT></SPLITINLINE>
  affect the answer? Does it affect the time to find an answer?  If you
  think it matters, demonstrate a faster program obtained from the given
  one by reordering the restrictions.  If you think it does not matter,
  argue your case.
  <LABEL NAME="ex:better-multiple-dwelling1"/>
      </EXERCISE>

      <EXERCISE>
  In the multiple dwelling problem, how many sets of assignments are
  there of people to floors, both before and after the requirement that
  floor assignments be distinct?  It is very inefficient to generate all
  possible assignments of people to floors and then leave it to
  backtracking to eliminate them.  For example, most of the restrictions
  depend on only one or two of the person-floor variables, and can thus
  be imposed before floors have been selected for all the people.
  Write and demonstrate a much more efficient
  nondeterministic
  <SPLITINLINE><SCHEME>procedure</SCHEME><JAVASCRIPT>function</JAVASCRIPT></SPLITINLINE>
  that solves this problem based upon
  generating only those possibilities that are not already ruled out by
  previous restrictions.  (Hint: This will require a nest of <SCHEMEINLINE>let</SCHEMEINLINE>
  expressions.)
  <LABEL NAME="ex:better-multiple-dwelling2"/>
      </EXERCISE>

      <EXERCISE>
  <INDEX>nondeterministic programming vs.<SPACE/>Scheme programming</INDEX>
  Write an ordinary Scheme program to solve the multiple dwelling puzzle.
      </EXERCISE>

      <EXERCISE>
  <INDEX>Phillips, Hubert</INDEX>
  Solve the following <QUOTE>Liars</QUOTE> puzzle (from <CITATION>Phillips 1934</CITATION>):

  <BLOCKQUOTE>
    Five schoolgirls sat for an examination.  Their parents<EMDASH/>so they
    thought<EMDASH/>showed an undue degree of interest in the result.  They
    therefore agreed that, in writing home about the examination, each 
    girl should make one true statement and one untrue one.  The following
    are the relevant passages from their letters:
    <UL>
      <LI>Betty: <QUOTE>Kitty was second in the examination.  I was only third.</QUOTE>
      </LI>
      <LI> Ethel: <QUOTE>You<APOS/>ll be glad to hear that I was on top.  Joan was second.</QUOTE>
      </LI>
      <LI>Joan: <QUOTE>I was third, and poor old Ethel was bottom.</QUOTE>
      </LI>
      <LI>Kitty: <QUOTE>I came out second.  Mary was only fourth.</QUOTE>
      </LI>
      <LI>Mary: <QUOTE>I was fourth.  Top place was taken by Betty.</QUOTE>
      </LI>
    </UL>
    What in fact was the order in which the five girls were placed?
  </BLOCKQUOTE>
      </EXERCISE>

      <EXERCISE>
  Use the <SCHEMEINLINE>amb</SCHEMEINLINE> evaluator to solve the following puzzle:<FOOTNOTE>This is taken from a booklet called <QUOTE>Problematical
      Recreations,</QUOTE> published in the 1960s by Litton Industries, where it
    is attributed to the <EM>Kansas State Engineer</EM>.</FOOTNOTE>

  <BLOCKQUOTE>
    Mary Ann Moore<APOS/>s father has a yacht and so has each of his four
    friends:  Colonel Downing, Mr. Hall, Sir Barnacle Hood, and Dr.
    Parker.  Each of the five also has one daughter and each has named his
    yacht after a daughter of one of the others.  Sir Barnacle<APOS/>s yacht is
    the Gabrielle, Mr. Moore owns the Lorna; Mr. Hall the Rosalind.  The
    Melissa, owned by Colonel Downing, is named after Sir Barnacle<APOS/>s
    daughter.  Gabrielle<APOS/>s father owns the yacht that is named after Dr.
    Parker<APOS/>s daughter.  Who is Lorna<APOS/>s father?
  </BLOCKQUOTE>
  Try to write the program so that it runs efficiently (see
  Exercise<SPACE/><REF NAME="ex:better-multiple-dwelling2"/>).  Also determine how many
  solutions there are if we are not told that Mary Ann<APOS/>s last name is
  Moore.
      </EXERCISE>
      <INDEX>puzzles<SUBINDEX>logic puzzles|)</SUBINDEX></INDEX>
      <INDEX>logic puzzles|)</INDEX>

      <EXERCISE>
  <INDEX>chess, eight-queens puzzle</INDEX><INDEX>eight-queens puzzle</INDEX>
  <INDEX>puzzles<SUBINDEX>eight-queens puzzle</SUBINDEX></INDEX>
  <INDEX>nondeterministic programming vs.<SPACE/>Scheme programming</INDEX>
  Exercise<SPACE/><REF NAME="ex:8queens"/> described the <QUOTE>eight-queens puzzle</QUOTE> of
  placing queens on a chessboard so that no two attack each other.
  Write a nondeterministic program to solve this puzzle.
      </EXERCISE>

      <SUBHEADING>
  <NAME>Parsing natural language</NAME>
      </SUBHEADING>

      <INDEX>parsing natural language|(</INDEX>
      <INDEX>nondeterministic programs<SUBINDEX>parsing natural language|(</SUBINDEX></INDEX>

      <TEXT>
  Programs designed to accept natural language as input usually start by
  attempting to <EM>parse</EM> the input, that is, to match the input
  against some grammatical structure.  For example, we might try to
  recognize simple sentences consisting of an article followed by a noun
  followed by a verb, such as <QUOTE>The cat eats.</QUOTE>  To accomplish such an
  analysis, we must be able to identify the parts of speech of
  individual words.  We could start with some lists that classify
  various words:<FOOTNOTE>Here we use the convention that the first element of each list
    designates the part of speech for the rest of the words in the list.</FOOTNOTE>

  <SNIPPET>
    <SCHEME>
      <!--  \indcode*{nouns} -->
      (define nouns '(noun student professor cat class))

      <!--  \indcode*{verbs} -->
      (define verbs '(verb studies lectures eats sleeps))

      <!--  \indcode*{articles} -->
      (define articles '(article the a))
    </SCHEME>
  </SNIPPET>
      </TEXT>

      <TEXT>
  <INDEX>grammar</INDEX>
  We also need a <EM>grammar</EM>, that is, a set of rules describing how
  grammatical elements are composed from simpler elements.  A very
  simple grammar might stipulate that a sentence always consists of two
  pieces<EMDASH/>a noun phrase followed by a verb<EMDASH/>and that a noun phrase
  consists of an article followed by a noun.  With this grammar, the
  sentence <QUOTE>The cat eats</QUOTE> is parsed as follows:

  <SNIPPET>
    <SCHEME>
      (sentence (noun-phrase (article the) (noun cat))
            (verb eats))
    </SCHEME>
  </SNIPPET>
      </TEXT>

      <TEXT>
  We can generate such a parse with a simple program that has separate
  <SPLITINLINE><SCHEME>procedures</SCHEME><JAVASCRIPT>functions</JAVASCRIPT></SPLITINLINE>
  for each of the grammatical rules.  To parse a sentence, we
  identify its two constituent pieces and return a list of
  these two elements, tagged with the symbol <SCHEMEINLINE>sentence</SCHEMEINLINE>:

  <!--  \ind{parse-@{\tt parse-...}|(}% -->
  <SNIPPET>
    <SCHEME>
      (define (parse-sentence)
      (list 'sentence
            (parse-noun-phrase)
            (parse-word verbs)))
    </SCHEME>
  </SNIPPET>
      </TEXT>

      <TEXT>
  A noun phrase, similarly, is parsed by finding an article followed by a
  noun:
  <SNIPPET>
    <SCHEME>
      (define (parse-noun-phrase)
      (list 'noun-phrase
            (parse-word articles)
            (parse-word nouns)))
    </SCHEME>
  </SNIPPET>
      </TEXT>

      <TEXT>
  At the lowest level, parsing boils down to repeatedly checking that
  the next unparsed word is a member of the list of words for the
  required part of speech.  To implement this, we maintain a global
  variable <SCHEMEINLINE>*unparsed*</SCHEMEINLINE>, which is the input that has not yet been
  parsed.  Each time we check a word, we require that <SCHEMEINLINE>*unparsed*</SCHEMEINLINE>
  must be non-empty and that it should begin with a word from the
  designated list.  If so, we remove that word from <SCHEMEINLINE>*unparsed*</SCHEMEINLINE> and
  return the word together with its part of speech (which is found at
  the head of the list):<FOOTNOTE>Notice that <SCHEMEINLINE>parse-word</SCHEMEINLINE> uses <SPLITINLINE><SCHEME><SCHEMEINLINE>set!</SCHEMEINLINE></SCHEME><JAVASCRIPT>assignment</JAVASCRIPT></SPLITINLINE> to modify the
    unparsed input list.  For this to work, our <SCHEMEINLINE>amb</SCHEMEINLINE> evaluator must
    undo the effects of <SPLITINLINE><SCHEME><SCHEMEINLINE>set!</SCHEMEINLINE></SCHEME><JAVASCRIPT>assignment</JAVASCRIPT></SPLITINLINE> operations when it backtracks.</FOOTNOTE>

  <SNIPPET>
    <SCHEME>
      (define (parse-word word-list)
      (require (not (null? *unparsed*)))
      (require (memq (car *unparsed*) (cdr word-list)))
      (let ((found-word (car *unparsed*)))
      (set! *unparsed* (cdr *unparsed*))
      (list (car word-list) found-word)))
    </SCHEME>
  </SNIPPET>
      </TEXT>

      <TEXT>
  To start the parsing, all we need to do is set <SCHEMEINLINE>*unparsed*</SCHEMEINLINE> to be
  the entire input, try to parse a sentence, and check that nothing is
  left over:

  <SNIPPET>
    <SCHEME>
      (define *unparsed* '())

      <!--  \indcode*{parse} -->
      (define (parse input)
      (set! *unparsed* input)
      (let ((sent (parse-sentence)))
      (require (null? *unparsed*))
      sent))
    </SCHEME>
  </SNIPPET>
      </TEXT>

      <TEXT>
  We can now try the parser and verify that it works for our simple test
  sentence:

  <SNIPPET>
    <SCHEMEOUTPUT>
      ;;; Amb-Eval input:
      (parse '(the cat eats))
      ;;; Starting a new problem
      ;;; Amb-Eval value:
      (sentence (noun-phrase (article the) (noun cat)) (verb eats))
    </SCHEMEOUTPUT>
  </SNIPPET>
      </TEXT>

      <TEXT>
  The <SCHEMEINLINE>amb</SCHEMEINLINE> evaluator is useful here because it is convenient to
  express the parsing constraints with the aid of <SCHEMEINLINE>require</SCHEMEINLINE>.
  Automatic search and backtracking really pay off, however, when we
  consider more complex grammars where there are choices for how the
  units can be decomposed.
      </TEXT>

      <TEXT>
  Let<APOS/>s add to our grammar a list of prepositions:

  <SNIPPET>
    <SCHEME>
      <!--  \indcode*{prepositions} -->
      (define prepositions '(prep for to in by with))
    </SCHEME>
  </SNIPPET>

  and define a prepositional phrase (e.g., <QUOTE>for the cat</QUOTE>) to be
  a preposition followed by a noun phrase:

  <SNIPPET>
    <SCHEME>
      (define (parse-prepositional-phrase)
      (list 'prep-phrase
            (parse-word prepositions)
            (parse-noun-phrase)))
    </SCHEME>
  </SNIPPET>
      </TEXT>

      <TEXT>
  Now we can define a sentence to be a noun phrase followed by a verb
  phrase, where a verb phrase can be either a verb or a verb phrase
  extended by a prepositional phrase:<FOOTNOTE>Observe that this
    definition is recursive<EMDASH/>a verb may be followed by any number
    of prepositional phrases.</FOOTNOTE>

  <SNIPPET>
    <SCHEME>
      (define (parse-sentence)
      (list 'sentence
            (parse-noun-phrase)
            (parse-verb-phrase)))

      (define (parse-verb-phrase)
      (define (maybe-extend verb-phrase)
      (amb verb-phrase
            (maybe-extend (list 'verb-phrase
            verb-phrase
            (parse-prepositional-phrase)))))
      (maybe-extend (parse-word verbs)))
    </SCHEME>
  </SNIPPET>
      </TEXT>

      <TEXT>
  While we<APOS/>re at it, we can also elaborate the definition of noun
  phrases to permit such things as <QUOTE>a cat in the class.</QUOTE>  What we used
  to call a noun phrase, we<APOS/>ll now call a simple noun phrase, and a noun
  phrase will now be either a simple noun phrase or a noun phrase
  extended by a prepositional phrase:

  <SNIPPET>
    <SCHEME>
      (define (parse-simple-noun-phrase)
      (list 'simple-noun-phrase
            (parse-word articles)
            (parse-word nouns)))

      (define (parse-noun-phrase)
      (define (maybe-extend noun-phrase)
      (amb noun-phrase
            (maybe-extend (list 'noun-phrase
            noun-phrase
            (parse-prepositional-phrase)))))
      (maybe-extend (parse-simple-noun-phrase)))
    </SCHEME>
  </SNIPPET>
  <!--  \ind{parse-@{\tt parse-...}|)}% -->
      </TEXT>

      <TEXT>
  Our new grammar lets us parse more complex sentences.  For example
  <SNIPPET>
    <SCHEME>
      (parse '(the student with the cat sleeps in the class))
    </SCHEME>
  </SNIPPET>

  produces

  <SNIPPET>
    <SCHEME>
      (sentence
      (noun-phrase
      (simple-noun-phrase (article the) (noun student))
      (prep-phrase (prep with)
            (simple-noun-phrase
            (article the) (noun cat))))
      (verb-phrase
      (verb sleeps)
      (prep-phrase (prep in)
            (simple-noun-phrase
            (article the) (noun class)))))
    </SCHEME>
  </SNIPPET>
      </TEXT>

      <TEXT>
  Observe that a given input may have more than one legal parse.  In
  the sentence <QUOTE>The professor lectures to the student with the cat,</QUOTE>
  it may be that the professor is lecturing with the cat, or that the
  student has the cat.  Our nondeterministic program finds both
  possibilities:

  <SNIPPET>
    <SCHEME>
      (parse '(the professor lectures to the student with the cat))
    </SCHEME>
  </SNIPPET>

  produces

  <SNIPPET>
    <SCHEME>
      (sentence
      (simple-noun-phrase (article the) (noun professor))
      (verb-phrase
      (verb-phrase
      (verb lectures)
      (prep-phrase (prep to)
            (simple-noun-phrase
            (article the) (noun student))))
      (prep-phrase (prep with)
            (simple-noun-phrase
            (article the) (noun cat)))))
    </SCHEME>
  </SNIPPET>
      </TEXT>

      <TEXT>
  Asking the evaluator to try again yields
  <SNIPPET>
    <SCHEME>
      (sentence
      (simple-noun-phrase (article the) (noun professor))
      (verb-phrase
      (verb lectures)
      (prep-phrase (prep to)
            (noun-phrase
            (simple-noun-phrase
            (article the) (noun student))
            (prep-phrase (prep with)
            (simple-noun-phrase
            (article the) (noun cat)))))))
    </SCHEME>
  </SNIPPET>

  <INDEX>nondeterministic programs<SUBINDEX>parsing natural language|)</SUBINDEX></INDEX>
      </TEXT>

      <EXERCISE>
  With the grammar given above, the following sentence can be parsed in
  five different ways:
  <QUOTE>The professor lectures to the student in the class with the cat.</QUOTE>
  Give the five parses and explain the differences in shades of
  meaning among them.
      </EXERCISE>

      <EXERCISE>
  <INDEX>nondeterministic evaluator<SUBINDEX>order of operand evaluation</SUBINDEX></INDEX>
  The evaluators in sections<SPACE/><REF NAME="sec:mc-eval"/> and <REF NAME="sec:lazy-evaluation"/>
  do not determine what order operands are evaluated in.
  We will see that the <SCHEMEINLINE>amb</SCHEMEINLINE> evaluator evaluates them from left to right.
  Explain why our parsing program wouldn<APOS/>t work if the operands were evaluated
  in some other order.
      </EXERCISE>

      <EXERCISE>
  Louis Reasoner suggests that, since a verb phrase is either a verb or
  a verb phrase followed by a prepositional phrase, it would be much more
  straightforward to define the
  <SPLITINLINE><SCHEME>procedure</SCHEME><JAVASCRIPT>function</JAVASCRIPT></SPLITINLINE>
  <SCHEMEINLINE>parse-verb-phrase</SCHEMEINLINE> as
  follows (and similarly for noun phrases):
  <SNIPPET>
    <SCHEME>
      (define (parse-verb-phrase)
      (amb (parse-word verbs)
      (list 'verb-phrase
            (parse-verb-phrase)
            (parse-prepositional-phrase))))
    </SCHEME>
  </SNIPPET>
  Does this work?  Does the program<APOS/>s behavior change if we interchange
  the order of expressions in the <SCHEMEINLINE>amb</SCHEMEINLINE>?
      </EXERCISE>

      <EXERCISE>
  Extend the grammar given above to handle more complex sentences.  For
  example, you could extend noun phrases and verb phrases to include
  adjectives and adverbs, or you could handle compound sentences.<FOOTNOTE>This kind of grammar can become arbitrarily complex, but it
    <INDEX>parsing natural language<SUBINDEX>real language understanding vs. toy parser</SUBINDEX></INDEX>
    is only a toy as far as real language understanding is concerned.
    Real natural-language understanding by computer requires an elaborate
    mixture of syntactic analysis and interpretation of meaning.  On the
    other hand, even toy parsers can be useful in supporting flexible
    command languages for programs such as information-retrieval systems.
    <INDEX>Winston, Patrick Henry</INDEX>
    <CITATION>Winston 1992</CITATION> discusses computational approaches to real
    language understanding and also the applications of simple grammars to
    command languages.</FOOTNOTE>
      </EXERCISE>

      <EXERCISE>
  <INDEX>generating sentences</INDEX>
  Alyssa P. Hacker is more interested in generating interesting
  sentences than in parsing them.  She reasons that by simply changing
  the
  <SPLITINLINE><SCHEME>procedure</SCHEME><JAVASCRIPT>function</JAVASCRIPT></SPLITINLINE>
  <SCHEMEINLINE>parse\?word</SCHEMEINLINE> so that it ignores the <QUOTE>input
    sentence</QUOTE> and instead always succeeds and generates an appropriate
  word, we can use the programs we had built for parsing to do
  generation instead.  Implement Alyssa<APOS/>s idea, and show the first
  half-dozen or so sentences generated.<FOOTNOTE>Although Alyssa<APOS/>s idea works just fine (and is
    surprisingly simple), the sentences that it generates are a bit
    boring<EMDASH/>they don<APOS/>t sample the possible sentences of this language in
    a very interesting way.  In fact, the grammar is highly recursive in
    many places, and Alyssa<APOS/>s technique <QUOTE>falls into</QUOTE> one of these recursions and
    gets stuck.  See Exercise<SPACE/><REF NAME="ex:ramb"/> for a way to deal with this.</FOOTNOTE>
  <LABEL NAME="ex:sentence-generate"/>
      </EXERCISE>
      <INDEX>parsing natural language|)</INDEX>
      <INDEX>nondeterministic computing|)</INDEX>

    </SUBSECTION>