      <SUBSECTION>
        
        <NAME>Orders of Growth</NAME>

        <LABEL NAME="sec:orders-of-growth"/>
        <INDEX>order of growth|(</INDEX>

        <TEXT>
          The previous examples illustrate that processes can differ
          considerably in the rates at which they consume computational
          resources.  One convenient way to describe this difference is to use
          the notion of 
          <INDEX>process<SUBINDEX>order of growth of</SUBINDEX></INDEX>
          <EM>order of growth</EM> to obtain a gross measure of the
          <INDEX>process<SUBINDEX>resources required by</SUBINDEX></INDEX>
          resources required by a process as the inputs become larger.
        </TEXT>

        <TEXT>
          Let <LATEXINLINE>$n$</LATEXINLINE> be a parameter that measures the size of the problem, 
          and let <LATEXINLINE>$R$</LATEXINLINE>(<LATEXINLINE>$n$</LATEXINLINE>) be the amount 
          of resources the process requires for a problem
          of size <LATEXINLINE>$n$</LATEXINLINE>.  In our previous examples we took 
          <LATEXINLINE>$n$</LATEXINLINE> to be the number
          for which a given function is to be computed, but there are other
          possibilities.  For instance, if our goal is to compute an
          approximation to the square root of a number, we might take 
          <LATEXINLINE>$n$</LATEXINLINE> to be
          the number of digits accuracy required.  For matrix multiplication we
          might take <LATEXINLINE>$n$</LATEXINLINE> to be the number of rows in the matrices. 
          In general there are a number of properties of the problem with respect to which
          it will be desirable to analyze a given process. 
          Similarly, <LATEXINLINE>$R$</LATEXINLINE>(<LATEXINLINE>$n$</LATEXINLINE>)
          might measure the number of internal storage registers used, the
          number of elementary machine operations performed, and so on.  In
          computers that do only a fixed number of operations at a time, the
          time required will be proportional to the number of elementary machine
          operations performed.
        </TEXT>

        <TEXT>
          <INDEX>theta@<LATEXINLINE>$\theta(f(n))$</LATEXINLINE> (theta of <LATEXINLINE>$f(n)$</LATEXINLINE>)</INDEX>
          <INDEX>order notation</INDEX>
          We say that <LATEXINLINE>$R(n)$</LATEXINLINE> has order of growth <LATEXINLINE>$\Theta(f(n))$</LATEXINLINE>, written
          <LATEXINLINE>$R(n)=\Theta(f(n))$</LATEXINLINE> (pronounced <QUOTE>theta of <LATEXINLINE>$f(n)$</LATEXINLINE></QUOTE>), if there are
          positive constants <LATEXINLINE>$k_1$</LATEXINLINE> and <LATEXINLINE>$k_2$</LATEXINLINE> independent of <LATEXINLINE>$n$</LATEXINLINE> such that
          <LATEX>
          $k_1f(n) \leq R(n) \leq k_2f(n)$
          </LATEX>
          for any sufficiently large value of <LATEXINLINE>$n$</LATEXINLINE>.  (In other
          words, for large <LATEXINLINE>$n$</LATEXINLINE>, 
          the value <LATEXINLINE>$R(n)$</LATEXINLINE> is sandwiched between 
          <LATEXINLINE>$k_1f(n)$</LATEXINLINE>
          and <LATEXINLINE>$k_2f(n)$</LATEXINLINE>.)
        </TEXT>

        <TEXT>
          <INDEX>order of growth<SUBINDEX>linear recursive process</SUBINDEX></INDEX>
          <INDEX>linear recursive process<SUBINDEX>order of growth</SUBINDEX></INDEX>
          <INDEX>recursive process<SUBINDEX>linear</SUBINDEX></INDEX>
          For instance, with the linear recursive process for computing
          factorial described in Section<SPACE/><REF NAME="sec:recursion-and-iteration"/> the
          number of steps grows proportionally to the input <LATEXINLINE>$n$</LATEXINLINE>.  Thus, the
          steps required for this process grows as <LATEXINLINE>$\Theta(n)$</LATEXINLINE>.  We also saw
          that the space required grows as <LATEXINLINE>$\Theta(n)$</LATEXINLINE>.
          <SPLIT>
            <SCHEME>
              For the 
          <INDEX>order of growth<SUBINDEX>linear iterative process</SUBINDEX></INDEX>
          <INDEX>linear iterative process<SUBINDEX>order of growth</SUBINDEX></INDEX>
          <INDEX>iterative process<SUBINDEX>linear</SUBINDEX></INDEX>
          iterative
          factorial, the number of steps is still <LATEXINLINE>$\Theta(n)$</LATEXINLINE> 
          but the space is
          <LATEXINLINE>$\Theta(1)$</LATEXINLINE><EMDASH/>that is, 
          constant.<FOOTNOTE>These statements mask a
            great deal of oversimplification.  For instance, if we count process
            steps as <QUOTE>machine operations</QUOTE> we are making the assumption that the
            number of machine operations needed to perform, say, a multiplication
            is independent of the size of the numbers to be multiplied, which is
            false if the numbers are sufficiently large.  Similar remarks hold for
            the estimates of space.  Like the design and description of a process,
            the analysis of a process can be carried out at various levels of
            abstraction.</FOOTNOTE> 
            </SCHEME>
            <JAVASCRIPT>
              For the 
          <INDEX>order of growth<SUBINDEX>linear iterative process</SUBINDEX></INDEX>
          <INDEX>linear iterative process<SUBINDEX>order of growth</SUBINDEX></INDEX>
          <INDEX>iterative process<SUBINDEX>linear</SUBINDEX></INDEX>
          iterative
          factorial function, the number of steps is still <LATEXINLINE>$\Theta(n)$</LATEXINLINE>.
          A properly tail-recursive implementation of Scheme will require space of
          <LATEXINLINE>$\Theta(1)$</LATEXINLINE><EMDASH/>that is, 
          constant space<EMDASH/>whereas JavaScript's space requirement for the iterative factorial function
          is still
          <LATEXINLINE>$\Theta(n)$</LATEXINLINE>.<FOOTNOTE>These statements mask a
            great deal of oversimplification.  For instance, if we count process
            steps as <QUOTE>machine operations</QUOTE> we are making the assumption that the
            number of machine operations needed to perform, say, a multiplication
            is independent of the size of the numbers to be multiplied, which is
            false if the numbers are sufficiently large.  Similar remarks hold for
            the estimates of space.  Like the design and description of a process,
            the analysis of a process can be carried out at various levels of
            abstraction.</FOOTNOTE> 
            </JAVASCRIPT>
          </SPLIT>
          The 
          <INDEX>order of growth<SUBINDEX>tree-recursive process</SUBINDEX></INDEX>
          <INDEX>tree-recursive process<SUBINDEX>order of growth</SUBINDEX></INDEX>
          <INDEX>recursive process<SUBINDEX>tree</SUBINDEX></INDEX>
          tree-recursive Fibonacci computation requires
          <LATEXINLINE>$\Theta(\phi^{n})$</LATEXINLINE> steps and space 
          <LATEXINLINE>$\Theta(n)$</LATEXINLINE>, where <LATEXINLINE>$\phi$</LATEXINLINE> is the
          golden ratio described in Section<SPACE/><REF NAME="sec:tree-recursion"/>.
        </TEXT>

        <TEXT>
          Orders of growth provide only a crude description of the behavior of a
          process.  For example, a process requiring <LATEXINLINE>$n^2$</LATEXINLINE> steps and a process
          requiring <LATEXINLINE>$1000n^2$</LATEXINLINE> steps and a process requiring <LATEXINLINE>$3n^2+10n+17$</LATEXINLINE> steps
          all have <LATEXINLINE>$\Theta(n^2)$</LATEXINLINE> order of growth.  On the other hand, order of
          growth provides a useful indication of how we may expect the behavior
          of the process to change as we change the size of the problem.  For a
          <INDEX>linear growth</INDEX>
          <LATEXINLINE>$\Theta(n)$</LATEXINLINE> (linear) process, doubling the size will roughly double the amount
          of resources used.  For an 
          <INDEX>exponential growth</INDEX>
          exponential process, each increment in
          problem size will multiply the resource utilization by a constant
          factor.  In the remainder of Section<SPACE/><REF NAME="sec:procedures-and-processes"/>
          we will examine two
          algorithms whose order of growth is 
          <INDEX>logarithmic growth</INDEX>
          logarithmic, so that doubling the
          problem size increases the resource requirement by a constant amount.
          <INDEX>order of growth|)</INDEX>
        </TEXT>

        <EXERCISE>
            Draw the tree illustrating the process generated by the 
            <SPLITINLINE><SCHEME><SCHEMEINLINE>count-change</SCHEMEINLINE></SCHEME>
              <JAVASCRIPT><JAVASCRIPTINLINE>count_change</JAVASCRIPTINLINE></JAVASCRIPT>
            </SPLITINLINE> 
            <SPLITINLINE><SCHEME>procedure</SCHEME><JAVASCRIPT>function</JAVASCRIPT></SPLITINLINE> 
            of Section<SPACE/><REF NAME="sec:tree-recursion"/> in making
            change for 11 cents.  What are the orders of growth of the space and
            number of steps used by this process as the amount to be changed
            increases?
        </EXERCISE>

        <EXERCISE>
          <INDEX>sine<SUBINDEX>approximation for small angle</SUBINDEX></INDEX>
          The sine of an angle (specified in
          radians) can be computed by making use of the approximation
          <LATEXINLINE>$\sin x\approx x$</LATEXINLINE>
          if <LATEXINLINE>$x$</LATEXINLINE> is
          sufficiently small, and the trigonometric identity 
          <LATEX>
              $\sin x=3\sin {x \over 3}-4\sin ^3{x \over 3}$
          </LATEX>
          to reduce the size of the argument of <LATEXINLINE>$\sin$</LATEXINLINE>.  (For
          purposes of this exercise an angle is considered <QUOTE>sufficiently
            small</QUOTE> if its magnitude is not greater than 0.1 radians.) These
          ideas are incorporated in the following 
          <SPLITINLINE><SCHEME>procedures</SCHEME><JAVASCRIPT>functions</JAVASCRIPT></SPLITINLINE>:
          <!-- \indcode*{cube} -->
          <SNIPPET PAGE="44">
            <NAME>sine_definition</NAME>
            <EXAMPLE>sine_example</EXAMPLE>
            <REQUIRES>abs_definition</REQUIRES>
            <SCHEME>
(define (cube x) (* x x x))

(define (p x)
   (- (* 3 x) (* 4 (cube x))))

(define (sine angle)
   (if (not (&gt; (abs angle) 0.1))
       angle
       (p (sine (/ angle 3.0)))))
            </SCHEME>
            <JAVASCRIPT>
function cube(x) {
    return x * x * x;
}
function p(x) {
    return 3 * x - 4 * cube(x);
}
function sine(angle) {
    return !(abs(angle) &gt; 0.1)
           ? angle
           : p(sine(angle / 3.0));
}
            </JAVASCRIPT>
          </SNIPPET>

        <SNIPPET PAGE="44" HIDE="yes">
          <NAME>sine_example</NAME>
          <REQUIRES>sine_definition</REQUIRES>
          <SCHEME>
(define pi 3.14159)
(sine (/ pi 2))
          </SCHEME>
          <JAVASCRIPT>
sine(math_PI / 2);
          </JAVASCRIPT>
        </SNIPPET>

        <OL>
          <LI>How many times is the
	  <SPLITINLINE><SCHEME>procedure</SCHEME><JAVASCRIPT>function</JAVASCRIPT></SPLITINLINE> <SCHEMEINLINE>p</SCHEMEINLINE> 
          applied when
	  <SPLITINLINE>
	    <SCHEME><SCHEMEINLINE>(sine 12.15)</SCHEMEINLINE></SCHEME>
	    <JAVASCRIPT><JAVASCRIPTINLINE>sine(12.15)</JAVASCRIPTINLINE></JAVASCRIPT>
	  </SPLITINLINE>
	  is evaluated?
        </LI>
        <LI>
        What is the order of growth in space and number of steps (as a
        function of<SPACE/><LATEXINLINE>$a$</LATEXINLINE>) used by the process generated by the <SCHEMEINLINE>sine</SCHEMEINLINE>
        <SPLITINLINE><SCHEME>procedure</SCHEME><JAVASCRIPT>function</JAVASCRIPT></SPLITINLINE>
	when
	<SPLITINLINE>
	  <SCHEME><SCHEMEINLINE>(sine a)</SCHEMEINLINE></SCHEME>
	  <JAVASCRIPT><JAVASCRIPTINLINE>sine(a)</JAVASCRIPTINLINE></JAVASCRIPT>
	</SPLITINLINE>
	is evaluated?
        </LI>
        </OL>
    <SOLUTION>
    <TEXT>
  <P>  a.) As stated, the function P will be called as long as the angle value is greater than 0.1.</P>
  <P>      Since, the angle is 12.15, the function P will be called 5 time.</P>
  <P>             after first function P call, angle value is 4.05</P>
  <P>             after second function P call,angle value is 1.35</P>
  <P>             after third function P call, angle value is 0.45</P>
  <P>             after fourth function P call,angle value is 0.15</P>
  <P>             after fifth function P call, angle value is 0.05 which is lesser than 0.1</P>
<P></P>
  <P>  b.) The order of growth in space and number of steps used by the process are both logarithmic in nature. </P>
  <P>      The growth will be of the order of <LATEXINLINE>$O(log_3(n))$</LATEXINLINE>and as can be seen it is a linear recursive process, the number of steps grows proportionally.</P>
                                            
    </TEXT>
  </SOLUTION>
        </EXERCISE>

      </SUBSECTION>
